{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c11c38b9-9697-4279-b733-c272ec11170d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting rake-nltk\n",
      "  Downloading rake_nltk-1.0.6-py3-none-any.whl.metadata (6.4 kB)\n",
      "Requirement already satisfied: scikit-learn in d:\\anaconda\\lib\\site-packages (1.2.2)\n",
      "Requirement already satisfied: nltk in d:\\anaconda\\lib\\site-packages (3.9.1)\n",
      "Requirement already satisfied: numpy>=1.17.3 in d:\\anaconda\\lib\\site-packages (from scikit-learn) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.3.2 in d:\\anaconda\\lib\\site-packages (from scikit-learn) (1.11.4)\n",
      "Requirement already satisfied: joblib>=1.1.1 in d:\\anaconda\\lib\\site-packages (from scikit-learn) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in d:\\anaconda\\lib\\site-packages (from scikit-learn) (2.2.0)\n",
      "Requirement already satisfied: click in d:\\anaconda\\lib\\site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: regex>=2021.8.3 in d:\\anaconda\\lib\\site-packages (from nltk) (2023.10.3)\n",
      "Requirement already satisfied: tqdm in d:\\anaconda\\lib\\site-packages (from nltk) (4.65.0)\n",
      "Requirement already satisfied: colorama in d:\\anaconda\\lib\\site-packages (from click->nltk) (0.4.6)\n",
      "Downloading rake_nltk-1.0.6-py3-none-any.whl (9.1 kB)\n",
      "Installing collected packages: rake-nltk\n",
      "Successfully installed rake-nltk-1.0.6\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "!pip install rake-nltk scikit-learn nltk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b471d8a8-74fc-4a0a-9944-1ca36929c6f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Required Libraries\n",
    "from rake_nltk import Rake\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import nltk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a5ea4adc-6e1e-4fc9-a0b3-433e7bc87edb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\lenov\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\lenov\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  First-time NLTK data download\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ab43ca09-af96-43ee-8c31-93ea4c770512",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"\n",
    "Natural language processing (NLP) is a subfield of linguistics, computer science, and artificial intelligence concerned \n",
    "with the interactions between computers and human language, in particular how to program computers to process and analyze \n",
    "large amounts of natural language data.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "51783a2e-0ec5-4332-bf6c-a8452221efa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#METHOD 1: Using RAKE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2386a0b7-6b72-409f-96e7-d64fe4a84850",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ”¹ Keywords using RAKE:\n",
      "\n",
      "1. artificial intelligence concerned\n",
      "2. analyze large amounts\n",
      "3. natural language processing\n",
      "4. natural language data\n",
      "5. human language\n",
      "6. computer science\n",
      "7. program computers\n",
      "8. computers\n",
      "9. subfield\n",
      "10. process\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nðŸ”¹ Keywords using RAKE:\\n\")\n",
    "\n",
    "rake = Rake()  # Initialize RAKE with default stopwords\n",
    "rake.extract_keywords_from_text(text)\n",
    "rake_keywords = rake.get_ranked_phrases()\n",
    "\n",
    "for i, kw in enumerate(rake_keywords[:10], 1):\n",
    "    print(f\"{i}. {kw}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "651f99da-0662-4fee-8277-b59d6e79c9a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#METHOD 2: Using TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7898f4ae-ebe4-4269-9649-d49a104a9cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We wrap the single document in a list to make it compatible\n",
    "corpus = [text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5ad02ecd-3f19-4e72-acb0-0c565e69edba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize TF-IDF Vectorizer\n",
    "tfidf = TfidfVectorizer(stop_words='english', max_features=10)\n",
    "X = tfidf.fit_transform(corpus)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
